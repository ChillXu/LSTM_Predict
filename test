#### 3. 信号量

信号量（Semaphore）是一个整型变量，可以对其执行 `down` 和 `up` 操作，也就是常见的 **P 和 V 操作**。

- **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0
- **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作

`down` 和 `up` 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候`屏蔽中断`。如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

```c
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

**使用信号量实现生产者-消费者问题** 

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

==注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下去，不会释放锁，消费者因此也会永远等待下去。==

```c
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```



#### 4. 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而`管程把控制的代码独立出来`，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```pascal
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
```

管程有一个**重要特性**：`在一个时刻只能有一个进程使用管程`。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了**条件变量**以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

**使用管程实现生产者-消费者问题**

```pascal
// 管程
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 then signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

// 生产者客户端
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```



### 7. 读者-写者问题

问题描述：允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```c
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```



### 8. 哲学家进餐问题

问题描述：五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```c
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        //state[i] = EATING;
        up(&s[i]);
    }
}
```



### 9. ※死锁

多个进程/线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于进程/线程被无限期地阻塞，因此程序不可能正常终止。



##### a. 死锁产生的四个必要条件：

1. **互斥**：`资源必须处于非共享模式`，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
2. **不剥夺**：`资源不能被抢占`，只能在持有资源的进程完成任务后，该资源才会被释放。
3. **请求和保持**：进程当前所拥有的资源在进程`请求其他新资源时`，由该进程`继续占有`。
4. **循环等待**：有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，......，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。



##### b. 解决死锁的方法：

1. **预防** 是采用某种策略，**限制并发进程对资源的请求**，从而使得死锁的必要条件在系统执行的任何时间上都不满足。

2. **避免** 则是系统在分配资源时，根据资源的使用情况**提前做出预测**，从而**避免死锁的发生**。
3. **检测** 是指系统设有**专门的机构**，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的进程和资源。
4. **恢复** 是与检测相配套的一种措施，用于**将进程从死锁状态中恢复过来**。



==鸵鸟策略：大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它==



### 10. 死锁的预防

破坏四个必要条件中的任何一个来预防死锁的发生。

+ **破坏互斥条件**：改造独占性资源为虚拟资源，大部分资源已无法改造。
+ **破坏不剥夺条件**：允许抢占资源，会导致**资源利用率下降**。
+ **破坏请求和保持条件**：采用`静态分配策略`，一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行。进程要么占有所有的资源然后开始执行，要么不占有资源，不会出现占有一些资源等待一些资源的情况。（这种策略**严重地降低了资源利用率**，因为在每个进程所占有的资源中，有些资源是在比较靠后的执行时间里采用的，甚至有些资源是在额外的情况下才是用的，这样就可能造成了一个进程占有了一些 **几乎不用的资源而使其他需要该资源的进程产生等待**的情况。）
+ **破坏循环等待条件**：实现资源有序分配策略，对所有资源实现分类编号，所有进程只能采用按序号递增的形式申请资源。



### 11. 死锁的避免

我们将系统的状态分为`安全状态`和`不安全状态` ，如果操作系统能够保证**所有的进程**在有限的时间内得到需要的全部资源，则称系统处于安全状态，否则说系统是不安全的。每当在未申请者分配资源前先测试系统状态，`若把系统资源分配给申请者会产生死锁，则拒绝分配`，否则接受申请，并为它分配资源。



##### 银行家算法

通过先 **试探** 分配给该进程资源，然后通过 **安全性算法** 判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入到安全的状态，则就 **真的分配资源给该进程**。

改善解决了 **资源使用率低的问题** ，但是它要不断地检测每个进程对各类资源的占用和申请情况，以及做 **安全性检查** ，需要花费较多的时间。



### 12. 死锁的检测 & 恢复

##### a. 检测

对资源的分配不加以任何限制，也不采取死锁避免措施，但系统 **定时地运行一个 “死锁检测”** 的程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它。

![进程-资源分配图](https://javaguide.cn/assets/%E8%BF%9B%E7%A8%8B-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE.31e353df.jpg)

用一个方框表示每一个资源类，方框中的黑点表示该资源类中的各个资源，每个键进程用一个圆圈表示，用 **有向边** 来表示 **进程申请资源和资源被分配的情况** 。

**检测步骤：**

1. 如果进程-资源分配图中无环路，则此时系统没有发生死锁；
2. 如果进程-资源分配图中有环路，且每个资源类仅有一个资源，则系统中已经发生了死锁；
3. 如果进程-资源分配图中有环路，且涉及到的资源类有多个资源，此时系统未必会发生死锁。如果能在进程-资源分配图中找出一个 **既不阻塞又非独立的进程** ，该进程能够在有限的时间内归还占有的资源，也就是把边给消除掉了，重复此过程，直到能在有限的时间内 **消除所有的边** ，则不会发生死锁，否则会发生死锁。



##### b. 恢复

1. **立即结束所有进程的执行，重新启动操作系统** ：这种方法简单，但以前所在的工作全部作废，损失很大。
2. **撤销涉及死锁的所有进程，解除死锁后继续运行** ：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
3. **抢占资源** ：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除



### 13. ※虚拟技术

虚拟技术把一个物理实体转换为多个逻辑实体。主要有两种虚拟技术：`时分复用技术`和`空分复用技术`。

**多进程与多线程：**使用了时分复用技术，多个进程能在同一个处理器上并发执行，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

**虚拟内存：**使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。



### 14. 局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

虚拟内存技术实际上就是建立了“内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。



### 15. 虚拟内存

**虚拟内存**是计算机系统内存管理的一种技术，`通过虚拟内存可以让程序可以拥有超过系统物理内存大小的可用内存空间`。另外，**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。



### 16. 虚拟内存的技术实现

**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。** 

虚拟内存的实现有以下三种方式：

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟内存功能而增加了`请求调页功能`和`页面置换功能`。**请求分页是目前最常用的一种实现虚拟存储器的方法**。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了`请求调段功能`、`分段置换功能`。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

不管是上面那种实现方式，我们一般都需要：

1. **一定容量的内存和外存**：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断**：如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换。



### 17. 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生`缺页中断`。当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做`页面置换算法`。

- **最佳页面置换算法（OPT）** ：所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现，一般作为`衡量其他置换算法的方法`。
- **先进先出页面置换算法（FIFO）**：总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **最近最久未使用页面置换算法（LRU，Least Recently Used）** ：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的。
- **最少使用页面置换算法（LFU，Least Frequently Used）**：选择在之前时期使用最少的页面作为淘汰页。
- **第二次机会算法**：对FIFO 算法做一个简单的修改，当页面被访问（读或写）时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端。
- **时钟**：第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。



### 18. ※内存管理

**操作系统的内存管理主要是做什么？**

操作系统的内存管理主要负责`内存的分配与回收`（malloc 函数：申请内存，free 函数：释放内存），以及`地址转换`也就是将逻辑地址转换成相应的物理地址。



### 19. 内存管理机制

+ 连续分配管理方式：**块式管理**（为一个用户程序分配一个连续的内存空间）

+ 非连续分配管理方式：**页式管理**、**段式管理**（允许一个程序使用的内存分布在离散或者说不相邻的内存中）

1. **块式管理** ： 远古时代的计算机操作系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：`把主存分为大小相等且固定的一页一页的形式`，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页并无任何实际意义。 段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如，有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式管理** ：段页式管理结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。



### 20. 分页 & 分段的共同点和区别

**共同点：**

+ 都是为了提高内存利用率，减少内存碎片。

- 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

**区别：**

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
- 分页仅仅是为了满足操作系统内存管理的需求（实现虚拟内存），而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。


### 21. 快表 & 多级页表

在分页内存管理中，很重要的两点是：

1. 虚拟地址到物理地址的转换要快；
2. 解决虚拟地址空间大，页表也会很大的问题。

##### a. 快表（TLB）

`为了提高虚拟地址到物理地址的转换速度`，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。`由于采用页表做地址转换，读写内存数据时 CPU 要访问两次内存`**（第一次访问内存中的页表，第二次根据页表查到具体的页表项，访问具体物理地址获取到物理块中内容）**。有了快表，`有时只要访问一次高速缓冲存储器，一次内存`，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。



##### b. 多级页表

引入多级页表的主要目的是为了`避免把全部页表一直放在内存中占用过多空间`，特别是那些根本就不需要的页表就不需要保留在内存中，`时间换空间`。



![img](https://img-blog.csdnimg.cn/2019101717363092.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p5MTM2NTE5NTM3ODQ=,size_16,color_FFFFFF,t_70)

假如虚拟地址空间为32位（即4GB）、每个页面映射4KB（用户进程被划分为若干个页）以及每条页表项占4B，则进程需要1M个页表项（`4GB / 4KB = 1M`），即页表占用4MB（`1M * 4B = 4MB`）的内存空间。而假如我们使用二级页表，还是上述条件，但一级页表映射4MB、二级页表映射4KB，则需要1K个一级页表项（`4GB / 4MB = 1K`）、每个一级页表项对应1K个二级页表项（`4MB / 4KB = 1K`），这样页表占用4.004MB（`1K * 4B + 1K * 1K * 4B = 4.004MB`）的内存空间。

**多级页表如何节约内存：**

1. **二级页表可以不存在；**

   如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了。

   页表一定要覆盖全部虚拟地址空间，因为如果虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。不分级的页表就需要有1M个页表项来映射，而二级页表则最少只需要1K个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

2. **二级页表可以不在主存。**

   可以把二级页表都放在磁盘中，在需要时才调入到内存。



### 22. 逻辑(虚拟)地址和物理地址

我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，`逻辑地址由操作系统决定`。`物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址`。物理地址是内存单元真正的地址。



### 23. CPU 寻址

现代处理器使用的是一种称为 **虚拟寻址（Virtual Addressing）** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit，MMU）** 的硬件。



没有虚拟地址空间的时候，**程序直接访问和操作的都是物理内存** 。但是这样有什么问题呢？

1. 用户程序可以`访问任意内存`，寻址内存的每个字节，这样就`很容易（有意或者无意）破坏操作系统`，造成操作系统崩溃。
2. 想要`同时运行多个程序特别困难`，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐`对内存的赋值就会覆盖微信之前所赋的值`，这就造成了微信这个程序就会崩溃。

**总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**



虚拟地址访问内存有以下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程`使用的虚拟地址彼此隔离`。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。



### 24. 内存分配（伙伴，slab）

Linux内核内存管理的一项重要工作就是如何在频繁`申请释放内存`的情况下，避免碎片的产生。Linux采用`伙伴系统`解决**外**部碎片的问题，采用`slab`解决**内**部碎片的问题。

1. 外部碎片是由于未分配的连续内存区域太小，以至于不能满足任意进程所需要的内存分配请求，这些小片段且不连续的内存空间被称为外部碎片。
2. 内部碎片是由于采用固定大小的内存分区，即以固定的大小块为单位来分配，采用这种方法，进程所`分配的内存可能会比所需要的大`，这多余的部分便是内部碎片。
   
   

避免外部碎片的方法有两种：
（1）是利用分页单元把一组非连续的空闲页框映射到连续的线性地址区间；
（2）伙伴系统：是记录现存空闲连续页框块情况，以尽量避免为了满足对小块的请求而分割大的连续空闲块。



##### a. 伙伴系统

原理：系统中的空闲内存总是两两分组，每组中的两个内存块称作伙伴。伙伴的分配可以是彼此独立的，但如果两个小伙伴都是空闲的，内核将其合并为一个更大的内存块，作为下一层次上某个内存块的伙伴。

![伙伴系统具体例子.png](https://img-blog.csdnimg.cn/83bb848551714c648aa9f7d0004e71bd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xsdW9qaWFu,size_16,color_FFFFFF,t_70)

这是一个最初由256KB的物理内存，内核需要请求21KB的内存。
那么最初他将256KB的内存进行分割，变成两个128KB的内存块，**AL和AR，这两个内存块称为伙伴**。 随后他发现128KB也远大于21KB，于是他继续分割为两个64KB的内存块，发现64KB 也不是满足需求的最小的内存块，于是他继续分割为两个32KB的。32KB再往下就是16KB，就不满足需求了，**所以32KB是它满足需求的最下的内存块了，所以他就分割出来的CL 或者CR 分配给需求方**。
当需求方用完了，需要进行归还，然后他把32KB的内存还回来，它的另一个伙伴如果没被占用，那么他们地址连续，就合并成一个64KB的内存块，以此类推，进行合并。**注意这里的所有的分割都是进行二分来分割，所有内存块的大小都是2的幂次方。**



**伙伴系统的缺点：**由于分配的都是2的幂次方的内存，会有内部碎片。



##### b. slab分配

slab是Linux操作系统的一种内存分配机制，针对一些经常分配并释放的对象，如进程描述符等，这些对象的大小一般比较小，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内存碎片，而且处理速度也太慢。slab分配器`基于对象进行管理`，相同类型的对象归为一类（如进程描述符就是一类），每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，Cache上会有已分配好的并标记为空闲的相应对象比如struct task_struct 来满足请求；当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。

 slab优点：

1. 可以提供小块内存的分配支持。

2. 不必每次申请释放都和伙伴系统打交道，提供了分配释放效率；
3. 如果在slab缓存的话，其在CPU高速缓存的概率也会较高；
4. 伙伴系统的操作对系统的数据和指令高速缓存有影响，slab分配器降低了这种副作用；
5. slab分配器通过着色使得slab对象能够均匀的使用高速缓存，提高高速缓存的利用率。

slab缺点：

- 对于微型嵌入式系统，它显得比较复杂，这时可以使用经过优化的slab分配器，它使用内存块链表，并使用最先适配算法；
- 对于具有大量内存的大型系统，仅仅建立slab分配器的数据结构就需要大量内存，这时候可以使用经过优化的slub分配器。



### ※25. Linux线程同步

##### a. 线程同步概念

假设有4个线程A、B、C、D，当前一个线程A对内存中的共享资源进行访问的时候，其他线程B，C，D都不可以对这块内存进行操作，直到线程A对这块内存访问完毕为止，B，C，D中的一个才能访问这块内存，剩余的两个需要继续阻塞等待，以此类推，直至所有的线程都对这块内存操作完毕。 线程对内存的这种访问方式就称之为线程同步，通过对概念的介绍，我们可以了解到所谓的`同步`并不是多个线程同时对内存进行访问，而`是按照先后顺序依次进行的`。



##### b. 为什么要同步

线程需要分时复用CPU时间片，并且如果测试程序中线程的CPU时间片没用完就被迫挂起了，这样就能让CPU的上下文切换（保存当前状态, 下一次继续运行的时候需要加载保存的状态）更加频繁，更容易再现数据混乱的这个现象。

[linux线程间同步（一）_梅山剑客的博客-CSDN博客_linux线程同步](https://blog.csdn.net/m0_46152793/article/details/123923667)

[Linux线程间同步（二）_梅山剑客的博客-CSDN博客](https://blog.csdn.net/m0_46152793/article/details/123925158?spm=1001.2014.3001.5502)

[Linux线程间同步（三）_梅山剑客的博客-CSDN博客](https://blog.csdn.net/m0_46152793/article/details/123925785?spm=1001.2014.3001.5502)











同步，原子操作，CAS&FAA，互斥锁，条件变量，RCU锁













CAS（Compare and Swap）先比较，再交换

FAA（Fetch And Add）先取值，然后进行增加

1. 
2. 底层IO模型，阻塞，非阻塞，信号，多路复用，异步
3. 多线程vs多进程；同一进程线程切换，不同进程线程切换
4. 协程vs线程
5. inode，软连接、硬连接，文件描述符
6. 零拷贝






# 数据结构 & 算法

### 1. 红黑树

**红黑树特点** :

1. 每个节点非红即黑；
2. 根节点总是黑色的；
3. 每个叶子节点都是黑色的空节点（NIL节点）；
4. 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；
5. 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。

**红黑树的应用** ：TreeMap、TreeSet以及JDK1.8的HashMap底层都用到了红黑树。

**为什么要用红黑树？** 简单来说红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。详细了解可以查看 [漫画：什么是红黑树？open in new window](https://juejin.im/post/5a27c6946fb9a04509096248#comment)（也介绍到了二叉查找树，非常推荐）



### 2. 排序

![十大排序算法](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/cs-basics/sorting-algorithms/sort1.png)

- **n**：数据规模
- **k**：“桶” 的个数
- **In-place**：占用常数内存，不占用额外内存
- **Out-place**：占用额外内存













