

情境（situation)、目标（target）、行动（action)、结果（result)



### 实习情况

华为云CloudBusinessCenter这边想建立一个AI一站式平台，通过AI应用提升内容管理、线上营销、智能运维的效率。从不同的域投入一定的人员来进行AI开发，我实习的组在结算域这边，负责结算业绩激励的相关业务，被分配到了这边做AI稽核相关的研究，想要首先初步实现异常数据的智能告警，后续能够精确识别，提前拦截。这边做AI相关开发的不多，学习起来阻力很大。



### Isolation-Forest

##### 1. 业务背景

**情境（situation)：**

在结算域业绩激励数据开发中，由于计费扣费等场景考虑遗漏、源数据缺失、配置信息错误问题，导致后端结算激励计算时，金额数据不准确（or标签错误），导致激励多发、少发，引发财控风险和客户投诉。

业绩激励数据的计算，涉及多个计算任务，期间的每个计算任务都有可能产生异常数据，且针对每一条结算业绩数据，包含有多个字段（customerid、name、productid、listprice、strikeprice等等）。传统上，对于业绩激励数据的重要中间过程表和结果表编写稽核监控任务流。

**缺点：**

1. 开发人员在编写稽核时，需要深入理解业务，由于业务场景复杂，很难覆盖所有业务场景；
2. 传统的稽核告警和业务强相关，新增或者修改特性，稽核要同步更新；
3. 对于数据源异常的情况，往往无法很好识别。



**目标（target）：**

需要一种高效的异常检测算法，完成对最终数据的稽核与诊断。



**行动（action)：**

1. 数据分析

   通过观察发现结算业绩激励数据具有以下特征：

   + 数据量较大，每日数据量约为10w
   + 单条记录内的不同的字段间存在相关性（横向相关）
   + 多条记录间的同一字段间存在相关性（纵向相关）
   + 异常数据的特征组合和正常数据的特征组合相比，具有一定差异性（即表现为离群特性），且异常数据总体占比较少。

2. 检测方法

   根据数据分析总结的特点，我们可以使用孤立异常点的算法，即不再描述正常的样本点，而选择孤立异常点。如果数据很容易被孤立出来，则认为当前数据是异常数据，选择Isolation-Forest算法来预测。

3. 算法原理

   假设数据集有N条数据，构建一颗iTree时，从N条数据中均匀抽样出ψ个样本出来，作为这颗树的训练样本。

   在样本中，随机选一个特征，并在这个特征的所有值范围内（最小值与最大值之间）随机选一个值，对样本进行划分，将样本中小于该值的划分到节点的左边，大于等于该值的划分到节点的右边。这样得到了一个分裂条件和左、右两边的数据集，然后分别在左右两边的数据集上重复上面的过程，直接达到终止条件。终止条件有两个，一个是数据本身不可再分(只包括一个样本，或者全部样本相同)，另外一个是树的高度达到log2(ψ)。

   通过构建一群树，每棵树都可以高效的把每个样本孤立出来，异常数据将拥有较短的平均孤立距离（孤立点离树根的距离）。
   $$
   2^{\frac {-E(h(x))}{c(n)}}
   \\h(x) 为 x 在每棵树的高度
   \\c(n) 为给定样本数 n 时路径长度的平均值,用来对样本 x 的路径长度 h(x) 进行标准化处理
   $$
   通过Isolation-Forest算法完成检测后，算法会给出一个异常度量值（iforest_score，**根据森林中所有iTree树的平均路径长度来计算，整合全部孤立树的结果**），因为面对实际的业务场景，算法算出来的异常度量值只能作为一个参考向，不能直接用来下判断，该数据为异常数据，所以通过设定一个异常值的下限0.14左右，高于的则标记为异常数据，统计异常数据在当日总数据量中的占比来进行告警。这也是目前算法的局限性，在数据量巨大的情况下，异常数据可能最多只有一两条，无法做到精准的告警。

   

**结果（result)：**

使用前一年的业绩激励数据训练Isolation-Forest模型，使用该方法对结算业绩激励数据进行检测，可成功检测出异常数据。现网成功告警，结算切换从公共服务获取云联盟站点信息，有一个点没有考虑到，导致有一天的业绩很多被算成了云联盟数据。



##### 2. 为什么选择Isolation-Forest算法？

孤立森林算法iForest 是[刘飞](https://feitonyliu.wordpress.com/about/)博士(Fei Tony Liu)在莫纳什大学就读期间由[陈开明](https://federation.edu.au/faculties-and-schools/faculty-of-science-and-technology/staff-profiles/information-technology/kai-ming-ting)(Kai-Ming Ting)教授和[周志华](http://cs.nju.edu.cn/zhouzh/)(Zhi-Hua Zhou)教授指导发表的。第一个版本是在2008年ICDM上，获得年度最佳论文，扩充版本发表于TKDD。

- 在大数据量（通过子采样缩小数据集）和小数据量均能取得较好效果；
- 具有线性时间复杂度，时间及空间复杂度较低；
- 在高维数据中，仍具有较好效果；
- 仅使用正常样本训练，仍能获得较好效果。



##### 3. 为什么进行子采样？

BI平台通过Hive SQL建立数据传输工作流到OBS桶，获得需要的每日结算数据。

每天大概会有将近10w条数据，一般8w多9w多，数据量太大，数据分布过于密集，Isolation-Forest算法很难孤立出各样本数据点，需要大量的分割操作。通过子采样缩小数据集，可以提高算法的可行性。对于样本量的选择，先从很小的数值开始，并逐渐增大（ψ = 2, 4, 8, 16, ..., 32768），实验结果发现，在数据量为1%的时候效果比较理想。



##### 4. 特征选择

+ 数量选择：与样本量选择类似，优先选择低维，从单一特征开始，逐渐增加；

+ 特征选择：优先选择峰度较高的特征。

  **峰度**，表征概率密度分布曲线在平均值处峰值高低的特征数

  **峰度高**，意味着方差增大是由低频度的大于或小于平均值的极端差值引起的



##### 5. 选取了哪些字段？

'客户类型'、'销售模式'、'消费类型'、'代金券扣款'、'现金券扣款'、org_price、final_price

```python
n_estimators：估算器(tree)数量300
max_samples：训练每个估算器(tree)需要抽取的样本数256 
```



##### 6. 怎么验证算法的效果？

通过人为的添加异常数据，数据数量、数据值*times



##### 7. 工程化流程

DAYU/DGC：周期性调度任务。

ModelArts：部署算法，利用OBS桶中的数据进行模型训练；**将模型预测结果导入到OBS桶中**。

OBS（对象存储服务）：存储中间数据。

Cloud BI（数据底座）：添加依赖项，建立传输任务工作流，将需要使用的训练数据导入到OBS桶中；**从OBS桶中获取模型预测结果，在BI平台—数据质量—规则管理，配置相关告警任务**。





### Prophet

从时序预测的角度



##### Prophet应用场景

1. 有至少几个月（最好是一年）的每小时、每天或每周观察的历史数据；
2. 有多种人类规模级别的较强的季节性趋势：每周的一些天和每年的一些时间；
3. 有事先知道的以不定期的间隔发生的重要节假日（比如国庆节）。
4. 缺失的历史数据或较大的异常数据的数量在合理范围内；
5. 有历史趋势的变化；
6. 对于数据中蕴含的非线性增长的趋势都有一个自然极限或饱和状态；
7. 对单个变量的值进行预测；



##### 数据处理

使用四分位数剔除异常值，通过Prophet算法得到未来一段时期的预测范围。

```
上四分位数：取3/4位置的数
下四分位数：取1/4位置的数
分位差 = 上四分位数 - 下四分位数
上界 = 上四分位数 + 1.5分位差
下界= 下四分位数 - 1.5分位差
```

异常检测就是将实际值与预测后的上限值进行比较，超过则认为是异常。

[Prophet时间序列原理及应用 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/257125885)

##### 算法缺点：

+ 当前算法适用于一些周期性或者趋势性比较强的时间序列；

+ 针对单序列建模，假如有1w条时间序列，需要有1w个Prophet模型，并且时间序列和时间序列之间的相关性无法被学习到。







LSTM

